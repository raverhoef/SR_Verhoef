{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b63db76e-fd1f-4e53-a7b6-170ca691604d",
   "metadata": {},
   "source": [
    "# Super-Resolution Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cd1f8f-390c-4e43-818e-0a0fccb41b8f",
   "metadata": {},
   "source": [
    "* Reference: https://github.com/sharmaroshan/Image-Super-Resolution/blob/master/Image%20Super%20Resolution%20with%20the%20SRCNN%20(Jupyter%20Notebook).ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d4d848-40c4-4cf9-bb81-7cfd69655542",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check package versions\n",
    "import sys, time\n",
    "import keras\n",
    "import cv2\n",
    "import numpy\n",
    "import matplotlib\n",
    "import skimage\n",
    "import tensorflow as tf\n",
    "\n",
    "print('Python: {}'.format(sys.version))\n",
    "print('Keras: {}'.format(keras.__version__))\n",
    "print('OpenCV: {}'.format(cv2.__version__))\n",
    "print('NumPy: {}'.format(numpy.__version__))\n",
    "print('Matplotlib: {}'.format(matplotlib.__version__))\n",
    "print('Scikit-Image: {}'.format(skimage.__version__))\n",
    "print('Tensorflow: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b8c692-7344-48ea-9d3a-07377450759b",
   "metadata": {},
   "source": [
    "* Reference: https://github.com/sharmaroshan/Image-Super-Resolution/blob/master/Image%20Super%20Resolution%20with%20the%20SRCNN%20(Jupyter%20Notebook).ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792013b1-0b88-43f2-87f3-563a1bcac2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate, Conv2DTranspose\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "\n",
    "# python magic function, displays pyplot figures in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2470bd-a78a-40d7-94aa-05458166833f",
   "metadata": {},
   "source": [
    "## Image quality metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`psnr()`:\n",
    "* Takes 2 arguments, `target` and `ref`\n",
    "* First converts the images to float data type to ensure accurate calculations, then it calculates the difference between the reference image and the target image.\n",
    "    * This difference is flattened into a one-dimensional array using the 'C' style, meaning it is read along rows, like in the C language.\n",
    "* The Root Mean Squared Error (RMSE) is then calculated by taking the square root of the mean of the squared differences.\n",
    "* Finally, the PSNR is calculated using the formula `20 * log10(MAX_I / RMSE)`, where `MAX_I` is the maximum possible pixel value of the image. (For an 8-bit RGB image, `MAX_I` is  255)\n",
    "\n",
    "`mse()`:\n",
    "* Takes 2 arguments, `target` and `ref`\n",
    "* Calculates the MSE between the two images, which is the sum of the squared differences between the corresponding pixels in the two images.\n",
    "    * This sum is then divided by the number of pixels in the target image to get the mean.\n",
    "* The result is the MSE, which is a measure of the average squared differences between the pixels of the two images.\n",
    "* Lower MSE values indicate higher similarity between the two images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c81c30f-1a43-441b-b4a7-b29b2c250b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defines function for peak signal-to-noise ratio (PSNR)\n",
    "def psnr(target, ref):\n",
    "        #assume RGB image\n",
    "        target_data = target.astype(float)\n",
    "        ref_data = ref.astype(float)\n",
    "        \n",
    "        diff = ref_data - target_data\n",
    "        diff = diff.flatten('C')\n",
    "        \n",
    "        rmse = math.sqrt(np.mean(diff ** 2.))\n",
    "        \n",
    "        return 20 * math.log10(255. / rmse)\n",
    "\n",
    "#defines function for mean squared error (MSE)\n",
    "def mse(target, ref):\n",
    "        #MSE between two images is the sum of the squared diffference between the two images\n",
    "        err = np.sum((target.astype('float') - ref.astype('float')) ** 2)\n",
    "        err /= float(target.shape[0] * target.shape[1])\n",
    "    \n",
    "        return err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88484993-8419-44ff-adad-7c596b24f96f",
   "metadata": {},
   "source": [
    "## Bicubic Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c0ffe8",
   "metadata": {},
   "source": [
    "### Reference: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1dfd85",
   "metadata": {},
   "source": [
    "* https://www.geeksforgeeks.org/python-opencv-bicubic-interpolation-for-resizing-image/\n",
    "* https://github.com/rootpine/Bicubic-interpolation/blob/master/bicubic.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14432354",
   "metadata": {},
   "source": [
    "### Interpolation Kernel Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`interpol_kernel()`:\n",
    "* Implements an interpolation kernel\n",
    "* Takes in two parameters: `s` and `a`\n",
    "    * `s` is the distance from the pixel center\n",
    "    * `a` is a parameter that controls the shape of the kernel.\n",
    "* Checks the absolute value of `s` and calculates the kernel value based on the conditions.\n",
    "* If the absolute value of `s` is between 0 and 1 inclusive, the function calculates the kernel value using the formula: `(a+2)*(abs(s)**3)-(a+3)*(abs(s)**2)+1`\n",
    "* If the absolute value of `s` is greater than 1 and less than or equal to 2, the function calculates the kernel value using the formula: `a*(abs(s)**3)-(5*a)*(abs(s)**2)+(8*a)*abs(s)-4*a`\n",
    "* If the absolute value of `s` is greater than 2, the function returns 0 as the kernel value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9362ad2-8c75-4e96-94c5-5cff379b2827",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interpolation kernel\n",
    "def interpol_kernel(s, a):\n",
    "    if (abs(s) >= 0) & (abs(s) <= 1):\n",
    "        return (a+2)*(abs(s)**3)-(a+3)*(abs(s)**2)+1\n",
    "    elif (abs(s) > 1) & (abs(s) <= 2):\n",
    "        return a*(abs(s)**3)-(5*a)*(abs(s)**2)+(8*a)*abs(s)-4*a\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94351453",
   "metadata": {},
   "source": [
    "#### Padding Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7a72fd",
   "metadata": {},
   "source": [
    "`padding()`:\n",
    "* Takes four parameters: `img`, `H`, `W`, and `C`\n",
    "    * `img` is the input image\n",
    "    * `H` and `W` are the height and width of the image\n",
    "    * `C` is the number of color channels in the image\n",
    "* First create a new zero-initialized numpy array `zimg` with dimensions `(H+4, W+4, C)`, which is larger than the input image by 4 pixels in both height and width.\n",
    "* It then copies the input image into the center of `zimg`, leaving a border of two pixels around the image.\n",
    "* Next, it pads the first and last two columns and rows of the image by copying the first and last columns and rows of the input image to the corresponding positions in the padded image.\n",
    "* Finally, it pads the four corners of the image by copying the corner pixels of the input image to the corresponding corner positions in the padded image.\n",
    "* The result is a new image that is the same as the input image but with a border of two pixels around it. The pixel values in the border are the same as the nearest pixel value in the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69152a0f-d63a-44ba-b32d-64e93b7065a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Padding\n",
    "def padding(img, H, W, C):\n",
    "    zimg = np.zeros((H+4, W+4, C))\n",
    "    zimg[2:H+2, 2:W+2, :C] = img\n",
    "    \n",
    "    #pad first/last two col and row\n",
    "    zimg[2:H+2, 0:2, :C] = img[:, 0:1, :C]\n",
    "    zimg[H+2:H+4, 2:W+2, :] = img[H-1:H, :, :]\n",
    "    zimg[2:H+2, W+2:W+4, :] = img[:, W-1:W, :]\n",
    "    zimg[0:2, 2:W+2, :C] = img[0:1, :, :C]\n",
    "    \n",
    "    #pad the missing eight points\n",
    "    zimg[0:2, 0:2, :C] = img[0, 0, :C]\n",
    "    zimg[H+2:H+4, 0:2, :C] = img[H-1, 0, :C]\n",
    "    zimg[H+2:H+4, W+2:W+4, :C] = img[H-1, W-1, :C]\n",
    "    zimg[0:2, W+2:W+4, :C] = img[0, W-1, :C]\n",
    "      \n",
    "    return zimg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0c74f8",
   "metadata": {},
   "source": [
    "### Bicubic Interpolation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506edcc0-9b03-474c-87ae-a0f7d5bf8b9b",
   "metadata": {},
   "source": [
    "`bicubic`:\n",
    "* Takes three parameters: `img`, `ratio`, and `a`.\n",
    "    * `img` is the input image\n",
    "    * `ratio` is the scaling factor\n",
    "    * `a` is a parameter that controls the shape of the interpolation kernel.\n",
    "* First retrieves the dimensions of the image `(H, W, C)`.\n",
    "* It then applies padding to the image using the `padding()` function.\n",
    "* Calculates the dimensions of the output image `(dH, dW)` based on the scaling ratio, and initializes a zero-filled numpy array `dst` of these dimensions.\n",
    "* Iterates over each color channel and each pixel in the output image. For each pixel, it calculates the corresponding coordinates in the input image `(x, y)`, and the weights for the four nearest horizontal and vertical neighbors using the `interpol_kernel()` function.\n",
    "* Then it retrieves the pixel values of the 16 nearest neighbors in the input image and calculates the value of the pixel in the output image by taking the dot product of the weights and pixel values.\n",
    "* If an error occurs during the interpolation process, the function catches the exception, prints an error message, and returns `None`. If the process completes successfully, the function returns the resized image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4032ca-c3f8-4be1-9db2-634657cade60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bicubic(img, ratio, a):\n",
    "    try:\n",
    "        #get image size\n",
    "        H, W, C = img.shape\n",
    "        #H = height, W = weight, C = number of channels if image is colored\n",
    "    \n",
    "        img = padding(img, H, W, C)\n",
    "    \n",
    "        #create new image\n",
    "        dH = math.floor(H*ratio)\n",
    "        dW = math.floor(W*ratio)\n",
    "    \n",
    "        #convert into matrix\n",
    "        dst = np.zeros((dH, dW, C)) #initialize dst as zero\n",
    "        #np.zeros generates a matrix consisting of only zeros\n",
    "    \n",
    "        h = 1/ratio\n",
    "    \n",
    "        print('Starting bicubic interpolation...')\n",
    "        inc = 0\n",
    "    \n",
    "        for c in range(C):\n",
    "            for j in range(dH):\n",
    "                for i in range(dW):\n",
    "                    #get coordinates of nearby values\n",
    "                    x, y = i * h + 2, j * h + 2\n",
    "                \n",
    "                    x_weights = np.array([interpol_kernel(1 + x - math.floor(x), a), interpol_kernel(x - math.floor(x), a),\n",
    "                                          interpol_kernel(math.floor(x) + 1 - x, a), interpol_kernel(math.floor(x) + 2 - x, a)])\n",
    "                    y_weights = np.array([interpol_kernel(1 + y - math.floor(y), a), interpol_kernel(y - math.floor(y), a),\n",
    "                                          interpol_kernel(math.floor(y) + 1 - y, a), interpol_kernel(math.floor(y) + 2 - y, a)])\n",
    "                \n",
    "                    # Considering all nearby 16 values\n",
    "                    x_floor = math.floor(x)\n",
    "                    y_floor = math.floor(y)\n",
    "                    pixel_values = img[y_floor-1:y_floor+3, x_floor-1:x_floor+3, c]\n",
    "\n",
    "                    #calculate the result for this pixel\n",
    "                    dst[j, i, c] = np.dot(np.dot(x_weights,pixel_values), y_weights)\n",
    "  \n",
    "        # If there is an error message, it directly goes to stderr\n",
    "        sys.stderr.write('\\n')\n",
    "      \n",
    "        # Flushing the buffer\n",
    "        sys.stderr.flush()\n",
    "        return dst\n",
    "    except Exception as e:\n",
    "        print(f\"Error during bicubic interpolation: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b633640e",
   "metadata": {},
   "source": [
    "## Normalize an image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98f14e0",
   "metadata": {},
   "source": [
    "`normalize()`:\n",
    "* Takes one parameter: `img` - the input image\n",
    "* Divides each pixel intensity value in the image by 255.0\n",
    "    * This is done because the maximum value for a pixel in an 8-bit grayscale image or any color channel in an RGB image is 255. By dividing this maximum value, all pixel values are brought into the range between 0 and 1.\n",
    "    * This normalized range is often easier for ML algorithms to work with and can help the algorithm converge faster.\n",
    "* Returns an image with normalized intensities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1d522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(img):\n",
    "    return img / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denormalize an image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662decff",
   "metadata": {},
   "source": [
    "`denormalize()`:\n",
    "* Takes one parameter: `img` - the input image\n",
    "* Multiplies each pixel intensity value in the image by 255.\n",
    "    * This reverses the effect of dividing by 255 during normalization.\n",
    "* Uses the `astype` method to convert the pixel values to the `np.uint8` data type (the standard data type for 8-bit image data).\n",
    "    * The `astype` method ensures that the pixel values are in the correct format for further image processing.\n",
    "* Returns a new image with denormalized intensities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88477a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(img):\n",
    "    return (img * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dbd0cd",
   "metadata": {},
   "source": [
    "## Prepare Image for Bicubic Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`process_image()`:\n",
    "* Takes four parameters: `img`, `index`, `output_folder`, and optional parameters `ratio` and `a`.\n",
    "    * `img` is the input image.\n",
    "    * `index` is used to name the output file.\n",
    "    * `output_folder` is the directory where the output file will be saved.\n",
    "    * `ratio` is the scaling factor for the bicubic interpolation.\n",
    "    * `a` is a parameter that controls the shape of the interpolation kernel.\n",
    "* It first checks if the input image is `None`, if it is then it raises a `ValueError`.\n",
    "* Prints the shape of the original image.\n",
    "* Normalizes the image using the `normalize()` function.\n",
    "    * scaling the pixel intensity values to the range between 0 and 1.\n",
    "* Performs bicubic interpolation on the normalized image using the `bicubic()` function.\n",
    "    * If the interpolation is successful, the function prints a success message.\n",
    "* It then denormalizes the interpolated image using the `denormalize()` function.\n",
    "    * Scaling the pixel intensity values back to their original range.\n",
    "* Checks if the output directory exists. If it doesn't, the function creates it.\n",
    "* Saves the denormalized image to a file in the output directory, and the file name is generated using the `index` parameter.\n",
    "* Reads the saved image file and prints its shape.\n",
    "* Finally, it returns the denormalized image.\n",
    "* If an error occurs at any point during the process, the function catches the exception, prints an error message, and returns `None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f063ac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img, index, output_folder=None, ratio=2, a=-1/2):\n",
    "    # Read image\n",
    "    try:\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Image could not be loaded.\")\n",
    "        \n",
    "        # display original image and its shape\n",
    "        #cv2.imshow('Original Image', img)\n",
    "        print('Original Image Shape:', img.shape)\n",
    "        #cv2.waitKey(0) # wait for a key press to close the window\n",
    "        \n",
    "        # normalize the image\n",
    "        normalized_img = normalize(img)\n",
    "\n",
    "        # Pass the input image in the \n",
    "        # bicubic function\n",
    "        dst = bicubic(normalized_img, ratio, a)\n",
    "        \n",
    "        if dst is not None:\n",
    "            print('Interpolation Completed!')\n",
    "\n",
    "            # denormalize the interpolated image\n",
    "            denormalized_dst = denormalize(dst)\n",
    "\n",
    "            # ensures the output folder exists\n",
    "            if not os.path.exists(output_folder):\n",
    "                os.makedirs(output_folder)\n",
    "            \n",
    "            # saving the output image\n",
    "            output_path = os.path.join(output_folder, f'bicubic_{index}.png')\n",
    "            cv2.imwrite(output_path, denormalized_dst) \n",
    "            print(f\"Interpolated image saved as {output_path}\")\n",
    "            \n",
    "            # display interpolated image and its shape\n",
    "            if denormalized_dst is not None:\n",
    "                #cv2.imshow('Bicubic Interpolation Image', denormalized_dst)\n",
    "                #cv2.waitKey(0) # wait for a key press to close the window\n",
    "                bicubicImg = cv2.imread(output_path)\n",
    "                print('Generated Bicubic Image Shape:', bicubicImg.shape)\n",
    "            \n",
    "            #cv2.destroyAllWindows() # close all OpenCV windows\n",
    "            return denormalized_dst\n",
    "        else:\n",
    "            print(\"Bicubic interpolation failed.\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde38bb1",
   "metadata": {},
   "source": [
    "## Load Image Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`load_images()`:\n",
    "* Takes two parameters: `folder_path` and `max_images`.\n",
    "    * `folder_path` is the path to the folder containing the image pairs.\n",
    "    * `max_images` is an optional parameter that specifies the maximum number of image pairs to load. If it is not provided or set to `None`, all image pairs in the folder will be loaded.\n",
    "* Starts by retrieving the names of all files in the specified folder.\n",
    "* Initializes two lists, `lr_images` and `hr_images`, to store the low-resolution and high-resolution images respectively.\n",
    "* If `max_images` is provided, the function reduces the list of file names to twice the number of `max_images`.\n",
    "    * This is because each image pair consists of two files: one for the low-resolution and one for the high-resolution image.\n",
    "* It then iterates over the list of file name. For each file name, it constructs the full file path and opens the image file. Converts the image to a numpy array, which is common for image data in ML.\n",
    "* It appends the image array to the appropriate list, depending on whether the image is a low-resolution or high-resolution image.\n",
    "    * It determines this based on the index of the file name in the list: even indices correspond to low-resolution images and odd indices correspond to high-resolution images.\n",
    "* Once all images have been loaded, the function converts the lists of images to numpy arrays and returns them.\n",
    "    * The first array contains the low-resolution images and the second array contains the high-resolution images.\n",
    "* If an error occurs while loading the images, the function will raise an exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872b06b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(folder_path, max_images=None):\n",
    "    # Get the file names in the folder\n",
    "    file_names = sorted(os.listdir(folder_path))\n",
    "\n",
    "    # Initialize lists to store the LR and HR images\n",
    "    lr_images = []\n",
    "    hr_images = []\n",
    "\n",
    "    # Limit the number of images to load if max_images is set\n",
    "    if max_images is not None:\n",
    "        file_names = file_names[:max_images * 2] # times 2 since there are LR and HR pairs\n",
    "\n",
    "    # Iterate over the file names\n",
    "    for i, file_name in enumerate(file_names):\n",
    "        # Exit the loop if the max number of image pairs has been loaded\n",
    "        if max_images is not None and (i // 2) >= max_images: # // 2 since there are LR and HR pairs\n",
    "            break\n",
    "\n",
    "        # Get the file path\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Open the image and convert it to a numpy array\n",
    "        image = Image.open(file_path)\n",
    "        image = np.array(image)\n",
    "\n",
    "        # Append the image to the appropriate list based on its index (even for LR, odd for HR)\n",
    "        if i % 2 == 0: # even index, LR image\n",
    "            lr_images.append(image)\n",
    "        else:\n",
    "            hr_images.append(image)\n",
    "\n",
    "    # Convert the lists to numpy arrays and return them\n",
    "    return np.array(lr_images), np.array(hr_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training dataset from folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28700bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_images_to_load = 5 #ADJUSTABLE NUMBER\n",
    "\n",
    "#train1_folder = 'G:\\My Drive\\SR_Verhoef\\Synthesis\\ImagePairs - Training Data (1 of 14)'\n",
    "train2_folder = 'G:\\My Drive\\SR_Verhoef\\Synthesis\\ImagePairs - Training Data (2 of 14)'\n",
    "\n",
    "X_train_lr, X_train_hr = load_images(train2_folder, max_images_to_load)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize all LR images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`resize_lr_images()`:\n",
    "* Takes two parameters: `image_array` and `target_size`.\n",
    "    * `image_array` is a numpy array containing the batch of images to be resized.\n",
    "    * `target_size` is a tuple specifying the target height and width for the resized images. If it is not provided, it defaults to `(512, 512)`\n",
    "* Starts by determining the total number of images in the batch (`num_images`). It then preallocates a numpy array `resized_images` to hold the resized images. The dimensions of this array are `(num_images, *target_size, 3)`, where `*target_size` is the target height and width, and `3` is the number of color channels. The data type of the array is `np.uint8`.\n",
    "* It then defines the output folder path where the processed images will be saved.\n",
    "* Next, it enters a loop where it processes each image in the batch. For each image, it calculates a unique index (`unique_index`), which is simply the current index of the loop.\n",
    "* Calls the `process_image()` function to process the current image by normalizing the image, perform bicubic interpolation to resize the image, denormalize the image, and saves the processed image to a file. The processed file is then saved to the corresponding position in the `resized_images` array.\n",
    "* Finally, after all images in the batch have been processed the function returns the `resized_images` array containing the resized images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b860d67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_lr_images(image_array, target_size=(512, 512), output_folder_path=None):\n",
    "    # total number of images\n",
    "    num_images = len(image_array)\n",
    "    output_folder = output_folder_path\n",
    "\n",
    "    # preallocate the array for resized images\n",
    "    resized_images = np.zeros((num_images, *target_size, 3), dtype=np.uint8)\n",
    "\n",
    "    if output_folder_path == None:\n",
    "        output_folder_path = 'G:\\My Drive\\SR_Verhoef\\Analysis\\Bicubic Result (training)'\n",
    "\n",
    "    # process each image in the current batch\n",
    "    for i, image in enumerate(image_array):\n",
    "        # calculate a unique index for each image\n",
    "        unique_index = i\n",
    "\n",
    "        print(\"Processing Image....\")\n",
    "        # process the image and save to the array of resized images\n",
    "        resized_image = process_image(image, unique_index, output_folder)\n",
    "        resized_images[i] = resized_image\n",
    "\n",
    "    return resized_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chopping LR images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`chop_lr_images()`:\n",
    "This functions chops a batch of low-resolution images into smaller segments. It is designed to work with image data in the form of numpy arrays.\n",
    "* Takes two parameters: `image_array` and `segment_size`.\n",
    "    * `image_array` is a numpy array containing the batch of images to be chopped.\n",
    "    * `segment_size` is an integer specifying the height and width of the segments. If it is not provided, it defaults to `255`.\n",
    "* Starts by initializing an empty list `mini_images` to store the segments.\n",
    "* Enters a loop where it processes each image in the batch. For each image, it retrieves the height and width of the image. It then calculates the number of segments in the x and y dimensions by integer division of the width and height by the `segment_size`.\n",
    "* Next, it enters nested loops over the x and y dimensions. For each x and y indices, it extracts a segment from the image. The segment is a square region of the image with size `segment_size`x `segment_size`, starting at the top-left corner `(j*segment_size, i*segment_size)` and ending at the bottom-right corner `((j+1)*segment_size, (i+1)*segment_size)`. It then appends the segment to the `mini_images` list.\n",
    "* Finally, after all images in the batch have been chopped into segments, the function converts the `mini_images` list to a numpy array and returns it. The returns array contains all the segments from all the images in the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chop_lr_images(image_array, segment_size=256):\n",
    "    #array to store mini images\n",
    "    mini_images = []\n",
    "\n",
    "    for img in image_array:\n",
    "        #Image dimensions\n",
    "        height, width = img.shape[:2]\n",
    "\n",
    "        #calculate the number of segments in each dimension\n",
    "        x_segments = width // segment_size\n",
    "        y_segments = height // segment_size\n",
    "\n",
    "        #chop the image into mini images\n",
    "        for i in range(x_segments):\n",
    "            for j in range(y_segments):\n",
    "                mini_img = img[j*segment_size:(j+1)*segment_size, i*segment_size:(i+1)*segment_size]\n",
    "                mini_images.append(mini_img)\n",
    "\n",
    "    return np.array(mini_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chopping HR images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`chop_hr_images()`:\n",
    "This function has the same process as the `chop_lr_images()` function, only with a different segment size of `512`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chop_hr_images(image_array, segment_size=512):\n",
    "    #array to store mini images\n",
    "    mini_images = []\n",
    "\n",
    "    for img in image_array:\n",
    "        #Image dimensions\n",
    "        height, width = img.shape[:2]\n",
    "\n",
    "        #calculate the number of segments in each dimension\n",
    "        x_segments = width // segment_size\n",
    "        y_segments = height // segment_size\n",
    "\n",
    "        #chop the image into mini images\n",
    "        for i in range(x_segments):\n",
    "            for j in range(y_segments):\n",
    "                mini_img = img[j*segment_size:(j+1)*segment_size, i*segment_size:(i+1)*segment_size]\n",
    "                mini_images.append(mini_img)\n",
    "\n",
    "    return np.array(mini_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9756e995-d1df-40c7-a783-34bcda020de9",
   "metadata": {},
   "source": [
    "## Build SCRNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9276bff",
   "metadata": {},
   "source": [
    "`build_srcnn()`:\n",
    "This function builds the Super-Resolution Convolutional Neural Network (SRCNN) model. \n",
    "* Takes two parameters: `input_layer` and `start_neurons`.\n",
    "    * `input_layer` is the input layer of the model (the input image).\n",
    "    * `start_neurons` is the number of neurons in the first layer of the model.\n",
    "* Starts by defining a series of convolutional layers and pooling layers, making up the contracting path of a U-Net Architecture, that downsamples the input image.\n",
    "    * Each convolutional layer applies a set of filters to the input data, and each pooling layer reduces the spatial dimensions of the data.\n",
    "    * The number of filters in each convolutional layer is a multiple of `start_neurons`, and the size of the filters decreases from `(7, 7)` to `(3, 3)` as the image is downsampled.\n",
    "    * The activation function for these layers is the Rectified Linear Unit (ReLU) function, which introduces non-linearity into the model.\n",
    "* After the downsampling layers, the function defines a 'middle' layer with a larger number of filters.\n",
    "    * This layer serves as a bottleneck that forces the model to learn a compressed representation of the input data.\n",
    "* Then it defines a series of upsampling layers that increases the resolution of the image.\n",
    "    * Each upsampling layer uses the `UpSampling2D` function to double the spatial dimensions of the data, and a `Concatenate` function to concatenate the upsampled data with the corresponding downsampling layer.\n",
    "    * This is followed by two convolutional layers that refine the upsampled data.\n",
    "    * The number of filters in these layers decreases from `start_neurons * 16` to `start_neurons * 1`, and the size of the filters increases from `(3, 3)` to `(7, 7)` as the image is upsampled.\n",
    "* Finally, the function defines an output layer that applies a linear activation function to the data.\n",
    "    * This layer has 3 filters of size 1, which corresponds to the 3 color channels of the output image.\n",
    "* The function returns the output layer of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ba2b45-588b-4235-b66d-04a80060082d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_srcnn(input_layer, start_neurons):\n",
    "\n",
    "    # 512 -> 256\n",
    "    conv1a = Conv2D(start_neurons * 1, (7, 7), activation=\"relu\", padding=\"same\")(input_layer)\n",
    "    conv1b = Conv2D(start_neurons * 1, (7, 7), activation=\"relu\", padding=\"same\")(conv1a)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1b)\n",
    "    \n",
    "    # 256 -> 128\n",
    "    conv2a = Conv2D(start_neurons * 2, (5, 5), activation=\"relu\", padding=\"same\")(pool1)\n",
    "    conv2b = Conv2D(start_neurons * 2, (5, 5), activation=\"relu\", padding=\"same\")(conv2a)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2b)\n",
    "    \n",
    "    # 128 -> 64\n",
    "    conv3a = Conv2D(start_neurons * 4, (5, 5), activation=\"relu\", padding=\"same\")(pool2)\n",
    "    conv3b = Conv2D(start_neurons * 4, (5, 5), activation=\"relu\", padding=\"same\")(conv3a)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3b)\n",
    "    \n",
    "    # 64 -> 32\n",
    "    conv4a = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(pool3)\n",
    "    conv4b = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(conv4a)\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4b)\n",
    "\n",
    "    # 32 -> 16\n",
    "    conv5a = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\")(pool4)\n",
    "    conv5b = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\")(conv5a)\n",
    "    pool5 = MaxPooling2D((2, 2))(conv5b)\n",
    "        \n",
    "    #middle\n",
    "    convm1 = Conv2D(start_neurons * 32, (3, 3), activation=\"relu\", padding=\"same\")(pool5)\n",
    "    convm2 = Conv2D(start_neurons * 32, (3, 3), activation=\"relu\", padding=\"same\")(convm1)\n",
    "        \n",
    "    #Upsampling\n",
    "    # 16 -> 32\n",
    "    up1 = UpSampling2D(size=(2, 2))(convm2)\n",
    "    concat1 = Concatenate(axis=3)([up1, conv5b])\n",
    "    conv6a = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\")(concat1)\n",
    "    conv6b = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\")(conv6a)\n",
    "    \n",
    "    # 32 -> 64\n",
    "    up2 = UpSampling2D(size=(2, 2))(conv6b)\n",
    "    concat2 = Concatenate(axis=3)([up2, conv4b])\n",
    "    conv7a = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(concat2)\n",
    "    conv7b = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(conv7a)\n",
    "    \n",
    "    # 64 -> 128\n",
    "    up3 = UpSampling2D(size=(2, 2))(conv7b)\n",
    "    concat3 = Concatenate(axis=3)([up3, conv3b])\n",
    "    conv8a = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(concat3)\n",
    "    conv8b = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(conv8a)\n",
    "   \n",
    "    # 128 -> 256\n",
    "    up4 = UpSampling2D(size=(2, 2))(conv8b)\n",
    "    concat4 = Concatenate(axis=3)([up4, conv2b])\n",
    "    conv9a = Conv2D(start_neurons * 2, (5, 5), activation=\"relu\", padding=\"same\")(concat4)\n",
    "    conv9b = Conv2D(start_neurons * 2, (5, 5), activation=\"relu\", padding=\"same\")(conv9a)\n",
    "\n",
    "    # 256 -> 512\n",
    "    up5 = UpSampling2D(size=(2, 2))(conv9b)\n",
    "    concat5 = Concatenate(axis=3)([up5, conv1b])\n",
    "    conv10a = Conv2D(start_neurons * 1, (7, 7), activation=\"relu\", padding=\"same\")(concat5)\n",
    "    conv10b = Conv2D(start_neurons * 1, (7, 7), activation=\"relu\", padding=\"same\")(conv10a)\n",
    "\n",
    "    #Output Layer\n",
    "    output_layer = Conv2D(3, 1, activation='linear')(conv10b)\n",
    "\n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e35145",
   "metadata": {},
   "source": [
    "## Create an Instance of this Model and Compile it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b264bd1",
   "metadata": {},
   "source": [
    "This code is used to create an compile a SRCNN model.\n",
    "* Starts by defining the shape of the input data, which is set to `(512, 512, 3)`.\n",
    "* Next, an input layer is created using the `Input` function from Keras. The shape of the input layer is set to the `input_shape` defined earlier.\n",
    "* It then sets the number of neurons in the first layer of the SRCNN model to 32. This is an adjustable value that can be tuned based on the specific requirments.\n",
    "* The SRCNN model is then instantiated by calling the `build_srcnn` function with the input layer and the number of starting neurons as arguments.\n",
    "* A Keras Model is then created using the `Model` function. The inputs to the model are set to the input layer, and the outputs are set to the output layer of the SRCNN model.\n",
    "* The model is then compiled using the `Adam` optimizer with a learning rate of 0.001, and the mean squared error loss function. The optimizer and loss function are set using the `compile` method of the Keras model.\n",
    "* Finally, the `summary` method is called on the model to print a summary of the model's architecture. This includes the number of layers in the model, the shape of the output from each layer, and the number of parameters in each layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e431de",
   "metadata": {},
   "source": [
    "#### Instance of Model and Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea9dcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjust size accordingly\n",
    "input_shape = (512, 512, 3)\n",
    "\n",
    "#create input layer\n",
    "input_layer = Input(shape=input_shape)\n",
    "\n",
    "#instantiate model\n",
    "start_neurons = 32 #adjustable value\n",
    "sr_model = build_srcnn(input_layer, start_neurons)\n",
    "\n",
    "#create the model\n",
    "model = Model(inputs=input_layer, outputs=sr_model)\n",
    "\n",
    "#compile the model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "#summary of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code Explained (TTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 'train_test_split' is used to split the datasets into training and testing (validation) sets.\n",
    "* 'X_train_lr' and 'X_train_hr' are the previously loaded and split LR and HR image arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chop LR and HR Images, then resize LR images with bicubic interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder_path = 'G:\\My Drive\\SR_Verhoef\\Analysis\\Bicubic Result (training)'\n",
    "\n",
    "lr_segments = chop_lr_images(X_train_lr)\n",
    "hr_segments = chop_hr_images(X_train_hr)\n",
    "#print(lr_segments)\n",
    "# Resize the lr_segments with bicubic interpolation method\n",
    "lr_segments = resize_lr_images(lr_segments, output_folder_path=output_folder_path)\n",
    "\n",
    "print(\"Size of lr_segments: \", lr_segments.shape)\n",
    "# Now, lr_segments and hr_segments are 2D arrays ready for training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Test, Split chopped images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c243868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_images.shape = (num_samples, height, width, channels)\n",
    "# hr_images.shape = (num_samples, height, width, channels)\n",
    "\n",
    "#split training data into training and validation sets\n",
    "X_train_lr, X_val_lr, X_train_hr, X_val_hr = train_test_split(\n",
    "    lr_segments,\n",
    "    hr_segments,\n",
    "    test_size=0.2, # 20% of the data will be used as the validation set\n",
    "    random_state=42, # ensures reproducibility of the split\n",
    "    shuffle=False # ensures the data isnt shuffled\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96aba0af",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27038e42",
   "metadata": {},
   "source": [
    "* Defines three callbacks used during the training process, applied at different stages.\n",
    "    * `ModelCheckpoint` saves the model after every epoch.\n",
    "    * `save_best_only` is set to `True`, meaning that the model is only saved if its performance on the validation set has improved since the last epoch.\n",
    "    * `ReduceLROnPlateau` reduces the learning rate when a metric has stopped improving.\n",
    "        * `factor` = 0.1, means the learning rate will reduce by a factor of 10.\n",
    "        * `patience` = 5, means that the learning rate will be reduced if the metric has not improved for 5 epochs.\n",
    "        * `min_lr` = 0.00001, is the lower bound on the learning rate.\n",
    "    * `EarlyStopping` stops training when a monitored metric has stopped improving.\n",
    "        * `patience` = 10, meaning the training will be stopped if the metric has not improved after 10 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a153273d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "#Callbacks\n",
    "checkpoint = ModelCheckpoint('model.h5', verbose=1, save_best_only=True)\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1)\n",
    "early_stopping = EarlyStopping(patience=10, verbose=1)\n",
    "\n",
    "#fit the model\n",
    "histroy = model.fit(\n",
    "    x=X_train_lr, # input low-resolution images\n",
    "    y=X_train_hr, # corresponding high-resolution images\n",
    "    validation_data=(X_val_lr, X_val_hr),\n",
    "    epochs=25, # number of epochs to train\n",
    "    batch_size=28, # number of samples per gradient update\n",
    "    callbacks=[checkpoint, reduce_lr, early_stopping],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803337bb",
   "metadata": {},
   "source": [
    "## Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee18fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test1_folder = 'G:\\My Drive\\SR_Verhoef\\Synthesis\\ImagePairs - Test Data (1 of 5)'\n",
    "bi_output_folder = 'G:\\My Drive\\SR_Verhoef\\Analysis\\Bicubic Interpolated Image Outputs (Testing)'\n",
    "max_images_to_load = 1\n",
    "\n",
    "# Split test data into lists\n",
    "Y_test_lr, Y_test_hr = load_images(test1_folder, max_images_to_load)\n",
    "\n",
    "# Chop images\n",
    "Y_test_lr = chop_lr_images(Y_test_lr)\n",
    "Y_test_hr = chop_hr_images(Y_test_hr)\n",
    "\n",
    "# Resize lr images\n",
    "Y_test_lr = resize_lr_images(Y_test_lr, output_folder_path=bi_output_folder)\n",
    "\n",
    "recombined_bi_image = np.block(Y_test_lr)\n",
    "\n",
    "# Saving the output image\n",
    "output_path = os.path.join(bi_output_folder, 'bicubic_final.png')\n",
    "cv2.imwrite(output_path, recombined_bi_image)\n",
    "print('Bicubic image saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate quality of resized lr images with psnr and mse\n",
    "bi_mse_values = []\n",
    "bi_psnr_values = []\n",
    "\n",
    "for i in range(len(Y_test_lr)):\n",
    "    bi_mse_value = mse(Y_test_hr[i], Y_test_lr[i])\n",
    "    bi_psnr_value = psnr(Y_test_hr[i], Y_test_lr[i])\n",
    "    bi_mse_values.append(bi_mse_value)\n",
    "    bi_psnr_values.append(bi_psnr_value)\n",
    "\n",
    "#Calculate average MSE and PSRN\n",
    "avg_mse_bi = np.mean(bi_mse_values)\n",
    "avg_psnr_bi = np.mean(bi_psnr_values)\n",
    "\n",
    "#Calculate standard deviation of MSE and PSNR\n",
    "bi_std_mse = np.std(bi_mse_values)\n",
    "bi_std_psnr = np.std(bi_psnr_values)\n",
    "\n",
    "print(\"Bicubic Average MSE: \", avg_mse_bi)\n",
    "print(\"Bicubic Average PSNR: \", avg_psnr_bi)\n",
    "print(\"Bicubic Standard Deviation of MSE: \", bi_std_mse)\n",
    "print(\"Bicubic Standard Deviation of PSNR: \", bi_std_psnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict(Y_test_lr)\n",
    "# Calculate MSE and PSNR\n",
    "mse_values = []\n",
    "psnr_values = []\n",
    "\n",
    "for i in range(len(Y_test_lr)):\n",
    "    mse_value = mse(Y_test_hr[i], Y_pred[i])\n",
    "    psnr_value = psnr(Y_test_hr[i], Y_pred[i])\n",
    "    mse_values.append(mse_value)\n",
    "    psnr_values.append(psnr_value)\n",
    "\n",
    "# Calculate average MSE and PSNR\n",
    "avg_mse = np.mean(mse_values)\n",
    "avg_psnr = np.mean(psnr_values)\n",
    "\n",
    "# Calculate standard deviation of MSE and PSNR\n",
    "std_mse = np.std(mse_values)\n",
    "std_psnr = np.std(psnr_values)\n",
    "\n",
    "print(\"SR Average MSE: \", avg_mse)\n",
    "print(\"SR Average PSNR: \", avg_psnr)\n",
    "print(\"SR Standard Deviation of MSE: \", std_mse)\n",
    "print(\"SR Standard Deviation of PSNR: \", std_psnr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output_folder = 'G:\\My Drive\\SR_Verhoef\\Analysis\\Final SRCNN ouput'\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "if not os.path.exists(final_output_folder):\n",
    "    os.makedirs(final_output_folder)\n",
    "\n",
    "# Save the super-resolution images\n",
    "for i in range(len(Y_pred)):\n",
    "    # Convert the image data to 8-bit per channel\n",
    "    img = np.clip(Y_pred[i], 0, 255).astype('uint8')\n",
    "\n",
    "    # Save the image with a formatted file name\n",
    "    file_name = f'output_image_{i}.png'\n",
    "    file_path = os.path.join(final_output_folder, file_name)\n",
    "    cv2.imwrite(file_path, img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recombine the final sr output\n",
    "recombined_sr_image = np.block(Y_pred)\n",
    "# saving the output image\n",
    "output_path = os.path.join(final_output_folder, f'bicubic_final.png')\n",
    "cv2.imwrite(output_path, recombined_sr_image)\n",
    "print('Final SR image saved!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
